<!-- # ğŸš€ Scrapify (Beta)

> AI-powered web scraping platform â€“ built as our Final Year Project (FYP).  
> ğŸ“¦ This **beta version** includes demo/testing code only â€“ not the new production backend.

---

## ğŸ“‚ Overview

This repository contains the **beta code** for Scrapify, including:
- ğŸ§© Backend (`/backend`) â€” old test APIs using `api/scrape/route.js`
- ğŸŒ Frontend (`/frontend`) â€” basic Next.js interface to scrape data & show AI summaries

âš  **Note:** This is only for **testing and code demonstration**.  
The production version (in progress) will include:
- Secure authentication (OAuth 2.0, JWT)
- Rate limiting & advanced security
- Optimized multi-page scraping
- AI-powered data enrichment

---

## ğŸ›  Features in Beta

âœ… Scrape metadata, text, images, links, and videos  
âœ… AI summarization of scraped data (using Hugging Face)  
âœ… Rule-based categorization & keyword extraction  
âœ… Store scraped data in MongoDB  
âœ… Frontend form & scrape history view  
âœ… Download data in JSON

---

## âš™ Tech Stack

| Layer     | Tech                                                         |
|----------|---------------------------------------------------------------|
| Frontend | **Next.js**, **React.js**, **Tailwind CSS**                   |
| Backend  | **Node.js**, **Express.js**, **Puppeteer**                    |
| Database | **MongoDB** & **Mongoose**                                    |
| AI       | **Hugging Face API** for summarization                        |

---

## ğŸ“¦ Getting Started (Beta)

### ğŸ”§ Backend

```bash
cd backend
npm install

Create .env file in /backend:

PORT=5000
MONGODB_URI=your_mongodb_connection_string
HUGGINGFACE_API_KEY=your_huggingface_api_key

Run locally:

npm run dev

The backend will run at: http://localhost:5000

### ğŸŒ Frontend 

cd frontend
npm install
Run locally:


npm run dev
The frontend will run at: http://localhost:3000

### ğŸš€ Build & Deploy  
For backend: deploy to Render / Railway / AWS
For frontend: build and deploy to Vercel


# Frontend production build
npm run build
npm start


### ğŸ¤ Contribution & Feedback 
As this is a beta release, we welcome feedback and testers!
ğŸ‘‰ Please open an issue or pull request.

### ğŸ“„ License
This project is part of our Final Year Project (FYP) and is shared for educational & testing purposes only. -->









ğŸš€ Scrapify (Beta)

AI-powered web scraping platform â€“ built as our Final Year Project (FYP).ğŸ“¦ Beta version only: contains demo/testing code â€” not the new production backend.

ğŸ“‚ Overview

This repository includes:

ğŸ§© Backend (/backend) â€“ old test APIs (api/scrape/route.js)

ğŸŒ Frontend (/frontend) â€“ basic Next.js interface to scrape data & show AI summaries

âš  Note: This code is only for testing & demonstration.Production version (in progress) will have:

Secure authentication (OAuth 2.0, JWT)

Rate limiting & better security

Optimized multi-page scraping

AI-powered data enrichment

ğŸ›  Features in Beta

âœ… Scrape metadata, text, images, links & videosâœ… AI summarization using Hugging Faceâœ… Rule-based categorization & keyword extractionâœ… Store data in MongoDBâœ… Frontend scrape form & history viewâœ… Download scraped data as JSON

âš™ Tech Stack

Layer

Tech

Frontend

Next.js, React.js, Tailwind CSS

Backend

Node.js, Express.js, Puppeteer

Database

MongoDB & Mongoose

AI

Hugging Face API

ğŸ“¦ Getting Started (Beta)

ğŸ”§ Backend

cd backend
npm install

Create .env file inside /backend:

PORT=5000
MONGODB_URI=your_mongodb_connection_string
HUGGINGFACE_API_KEY=your_huggingface_api_key

Run locally:

npm run dev

The backend will run at: http://localhost:5000

ğŸŒ Frontend

cd frontend
npm install
npm run dev

The frontend will run at: http://localhost:3000

ğŸš€ Build & Deploy

Backend: deploy to Render / Railway / AWS

Frontend: deploy to Vercel

For frontend production build:

npm run build
npm start

ğŸ¤ Contribution & Feedback

This is a beta release â€” testers & feedback are welcome!ğŸ‘‰ Open an issue or create a pull request.

ğŸ“„ License

Built as part of our Final Year Project (FYP) and shared for educational & testing purposes only.

